{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "import nltk\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from nltk.metrics.scores import f_measure\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text: str) -> str:\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\n",
    "    Copied from the [QuAC](http://quac.ai/) evaluation script found at\n",
    "    https://s3.amazonaws.com/my89public/quac/scorer.py\"\"\"\n",
    "\n",
    "    def remove_articles(text: str) -> str:\n",
    "        return re.sub(r\"\\b(a|an|the)\\b\", \" \", text)\n",
    "\n",
    "    def white_space_fix(text: str) -> str:\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text: str) -> str:\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text: str) -> str:\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(text))))\n",
    "\n",
    "def f1_score(gold: str, pred: str) -> float:\n",
    "    ret = f_measure(set(normalize_text(gold).split()), set(normalize_text(pred).split()))\n",
    "    if ret is None:\n",
    "        return 0.0\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=\"gsm\"\n",
    "folder_path = f\"../../data/raw_data/{dataset}\"\n",
    "answer_map = {\" A\": 0, \" B\": 1, \" C\": 2, \" D\": 3, \"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
    "final = []\n",
    "file_list = os.listdir(folder_path)\n",
    "json_files = [file for file in file_list if file.endswith(\".json\")]\n",
    "json_files = sorted(json_files, key=lambda x: len(x))\n",
    "scorer = rouge_scorer.RougeScorer(['rouge2'], use_stemmer=True)\n",
    "json_files = json_files[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "CSV file 'triples.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "def extract_number_from_text(text):\n",
    "    match = re.search(r'The answer is (\\d+)', text)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "for file_id, file_name in enumerate(json_files):\n",
    "    print(file_id)\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "        method = data[\"adapter_spec\"][\"method\"]\n",
    "        if method == 'generation':\n",
    "            for qid, rs in enumerate(data[\"request_states\"]):\n",
    "                candidate = rs[\"result\"][\"completions\"][0][\"text\"]\n",
    "                candidate_number = extract_number_from_text(candidate)\n",
    "                label = 0\n",
    "                for i in range(len(rs[\"instance\"][\"references\"])):\n",
    "                    reference = rs[\"instance\"][\"references\"][i][\"output\"][\"text\"]\n",
    "                    reference_number = extract_number_from_text(reference)\n",
    "                    if candidate_number is not None and reference_number is not None:\n",
    "                        if candidate_number == reference_number:\n",
    "                            label = 1\n",
    "                            break\n",
    "                insert = {\"s_id\": file_id, \"q_id\": qid, \"label\": label}\n",
    "                final.append(insert)\n",
    "        elif method == 'ranking_binary':\n",
    "            for k in range(0, len(data[\"request_states\"]),60):\n",
    "                RR_score=0\n",
    "                rank=data[\"request_states\"][k][\"instance\"][\"references\"]\n",
    "                for t in range(10):\n",
    "                    if len(rank[t][\"tags\"])>2:\n",
    "                        RR_score=1/t\n",
    "                        break\n",
    "                insert = {\"s_id\": file_id, \"q_id\": k/60, \"label\": RR_score}\n",
    "                print(insert)\n",
    "                final.append(insert)\n",
    "        else:\n",
    "            for qid, rs in enumerate(data[\"request_states\"]):\n",
    "                Answer = 0\n",
    "                for ans in rs[\"instance\"][\"references\"]:\n",
    "                    if len(ans[\"tags\"]) > 0:\n",
    "                        break\n",
    "                    else:\n",
    "                        Answer = Answer + 1\n",
    "                result = rs[\"result\"][\"completions\"][0][\"text\"]\n",
    "                if result in answer_map:\n",
    "                    res = answer_map[result]\n",
    "                else:\n",
    "                    res = 999\n",
    "                label = 0\n",
    "                if res == Answer:\n",
    "                    label = 1\n",
    "                insert = {\"s_id\": file_id, \"q_id\": qid, \"label\": label}\n",
    "                final.append(insert)\n",
    "\n",
    "\n",
    "def json_to_csv(data, csv_file):\n",
    "    with open(csv_file, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"model_id\", \"question_id\", \"correct\"])\n",
    "\n",
    "        for item in data:\n",
    "            s_id = item[\"s_id\"]\n",
    "            q_id = item[\"q_id\"]\n",
    "            correct = item[\"label\"]\n",
    "            writer.writerow([s_id, q_id, correct])\n",
    "\n",
    "    print(f\"CSV file '{csv_file}' created successfully.\")\n",
    "\n",
    "json_to_csv(final, \"triples.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_unique(data: pd.DataFrame, key):\n",
    "    if key is None:\n",
    "        print(\"Total length: {}\".format(len(data)))\n",
    "    elif isinstance(key, str):\n",
    "        print(\"Number of unique {}: {}\".format(key, len(data[key].unique())))\n",
    "        return len(data[key].unique())\n",
    "    elif isinstance(key, list):\n",
    "        print(\n",
    "            \"Number of unique [{}]: {}\".format(\n",
    "                \",\".join(key), len(data.drop_duplicates(key, keep=\"first\"))\n",
    "            )\n",
    "        )\n",
    "        return len(data.drop_duplicates(key, keep=\"first\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_id  question_id  correct\n",
       "0         0            0        0\n",
       "1         0            1        0\n",
       "2         0            2        0\n",
       "3         0            3        1\n",
       "4         0            4        0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.read_csv(\"triples.csv\", encoding = 'utf-8', dtype={'skill_id': str})\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length: 7000\n",
      "Number of unique [model_id,question_id]: 7000\n",
      "Number of unique model_id: 5\n",
      "Number of unique question_id: 3000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_unique(all_data, None)\n",
    "stat_unique(all_data, ['model_id', 'question_id'])\n",
    "stat_unique(all_data, 'model_id')\n",
    "stat_unique(all_data, 'question_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter 3000 questions\n"
     ]
    }
   ],
   "source": [
    "# filter questions\n",
    "n_models = selected_data.groupby('question_id')['model_id'].count()\n",
    "question_filter = n_models[n_models < 50].index.tolist()\n",
    "print(f'filter {len(question_filter)} questions')\n",
    "selected_data = selected_data[~selected_data['question_id'].isin(question_filter)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter 0 models\n"
     ]
    }
   ],
   "source": [
    "# filter models\n",
    "n_questions = selected_data.groupby('model_id')['question_id'].count()\n",
    "model_filter = n_questions[n_questions < 10].index.tolist()\n",
    "print(f'filter {len(model_filter)} models')\n",
    "selected_data = selected_data[~selected_data['model_id'].isin(model_filter)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renumber the models\n",
    "s2n = {}\n",
    "cnt = 0\n",
    "for i, row in selected_data.iterrows():\n",
    "    if row.model_id not in s2n:\n",
    "        s2n[row.model_id] = cnt\n",
    "        cnt += 1\n",
    "selected_data.loc[:, 'model_id'] = selected_data.loc[:, 'model_id'].apply(lambda x: s2n[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renumber the questions\n",
    "q2n = {}\n",
    "cnt = 0\n",
    "for i, row in selected_data.iterrows():\n",
    "    if row.question_id not in q2n:\n",
    "        q2n[row.question_id] = cnt\n",
    "        cnt += 1\n",
    "selected_data.loc[:, 'question_id'] = selected_data.loc[:, 'question_id'].apply(lambda x: q2n[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data.to_csv(\"triples.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "al={}\n",
    "cm = 20000\n",
    "for i in range(cm):\n",
    "    al[str(i)] = [i]\n",
    "json_file = \"./concept_map.json\"\n",
    "with open(json_file, \"w\") as file:\n",
    "    json.dump(al, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(data):\n",
    "\n",
    "    model_data = defaultdict(lambda: defaultdict(dict))\n",
    "    ques_data = defaultdict(lambda: defaultdict(dict))\n",
    "    for i, row in data.iterrows():\n",
    "        sid = row.model_id\n",
    "        qid = row.question_id\n",
    "        correct = row.correct\n",
    "        model_data[sid][qid] = correct\n",
    "        ques_data[qid][sid] = correct\n",
    "    return model_data, ques_data\n",
    "\n",
    "\n",
    "data = []\n",
    "for i, row in selected_data.iterrows():\n",
    "    data.append([row.model_id, row.question_id, row.correct])\n",
    "\n",
    "stu_data, ques_data = parse_data(selected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length: 7000\n",
      "Number of unique [model_id,question_id]: 7000\n",
      "Number of unique model_id: 5\n",
      "Number of unique question_id: 3000\n",
      "5 1\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.2\n",
    "least_test_length = 5\n",
    "\n",
    "stat_unique(selected_data, None)\n",
    "a = stat_unique(selected_data, [\"model_id\", \"question_id\"])\n",
    "b = stat_unique(selected_data, \"model_id\")\n",
    "c = stat_unique(selected_data, \"question_id\")\n",
    "\n",
    "\n",
    "n_students = len(stu_data)\n",
    "if isinstance(test_size, float):\n",
    "    test_size = int(n_students * test_size)\n",
    "train_size = n_students - test_size\n",
    "assert train_size > 0 and test_size > 0\n",
    "\n",
    "students = list(range(n_students))\n",
    "random.shuffle(students)\n",
    "if least_test_length is not None:\n",
    "    student_lens = defaultdict(int)\n",
    "    for t in data:\n",
    "        student_lens[t[0]] += 1\n",
    "    students = [\n",
    "        student for student in students if student_lens[student] >= least_test_length\n",
    "    ]\n",
    "test_students = set(students[:test_size])\n",
    "print(n_students, len(test_students))\n",
    "train_data = [record for record in data if record[0] not in test_students]\n",
    "test_data = [record for record in data if record[0] in test_students]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train records length: 6000\n",
      "test records length: 1000\n",
      "all records length: 7000\n"
     ]
    }
   ],
   "source": [
    "def renumber_student_id(data):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        data: list of triplets (sid, qid, score)\n",
    "\n",
    "    Returns:\n",
    "        renumbered datasets: list of triplets (sid, qid, score)\n",
    "    \"\"\"\n",
    "    student_ids = sorted(set(t[0] for t in data))\n",
    "    renumber_map = {sid: i for i, sid in enumerate(student_ids)}\n",
    "    data = [(renumber_map[t[0]], t[1], t[2]) for t in data]\n",
    "    return data\n",
    "\n",
    "\n",
    "train_data = renumber_student_id(train_data)\n",
    "test_data = renumber_student_id(test_data)\n",
    "all_data = renumber_student_id(data)\n",
    "\n",
    "print(f\"train records length: {len(train_data)}\")\n",
    "print(f\"test records length: {len(test_data)}\")\n",
    "print(f\"all records length: {len(all_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(data, path):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data: list of triplets (sid, qid, scoreRate)\n",
    "        path: str representing saving path\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame.from_records(\n",
    "        sorted(data), columns=[\"model_id\", \"question_id\", \"correct\"]\n",
    "    )\n",
    "    df[\"model_id\"] = df[\"model_id\"].astype(int)\n",
    "    df[\"question_id\"] = df[\"question_id\"].astype(int)\n",
    "    df.to_csv(path, index=False)\n",
    "\n",
    "save_to_csv(\n",
    "    train_data, \"train_triples.csv\"\n",
    ")\n",
    "save_to_csv(\n",
    "    test_data, \"test_triples.csv\"\n",
    ")\n",
    "save_to_csv(all_data, \"triples.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    \"num_models\": n_students,\n",
    "    \"num_questions\": c,\n",
    "    \"num_concepts\":20000,\n",
    "    \"num_records\": len(all_data),\n",
    "    \"num_train_students\": n_students - len(test_students),\n",
    "    \"num_test_students\": len(test_students),\n",
    "\n",
    "}\n",
    "\n",
    "with open(\"metadata.json\", \"w\") as f:\n",
    "    json.dump(metadata, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
